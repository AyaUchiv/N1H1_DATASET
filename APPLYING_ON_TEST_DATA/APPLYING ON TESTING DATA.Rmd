---
title: "H1N1_2"
author: "AYA"
date: "2025-03-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# CLEAR THE ENVIRONMENT
```{r}
rm(list  =ls())
```

# LOAD THE NECESSARY LIBRARIES
```{r}
library(mlbench)
library(caret)
install.packages("caTools")
library(caTools)
install.packages("ranger")
library(ranger)
library(dplyr)
install.packages("doParallel")
library(doParallel)
```

# LOAD THE DATASET
```{r}
#load the training features
training_features <- read.csv("training_set_features.csv", row.names = 1, header = T, stringsAsFactors = T)
View(training_features)
```

```{r}
#load the validation labels
training_labels <- read.csv("training_set_labels.csv", row.names = 1, header = T, stringsAsFactors = T)
#View(training_labels)
```

```{r}
#combining labels
h1n1 <- cbind(training_features, training_labels[1:2])
```

```{r}
View(h1n1)
```

# DATA CLEANING
```{r}
#sum of all NA values in each dataset
colSums(is.na(h1n1))
```
health insurance has the largest NA values 12274. Filling up thr data might cause inaccuracies so we will drop the column "health_insurance".
```{r}
#removing "health_insurance" column from the dataset
h1n1$health_insurance <- NULL

#also dropping "hhs_goe_region", "employment_industry" and "employment_occupation"
h1n1$hhs_geo_region <- NULL
h1n1$employment_industry <- NULL
h1n1$employment_occupation <- NULL

#View(h1n1)
```

```{r}
#dropping all NA values in the dataset
h1n1 <- na.omit(h1n1)

#checking the dimension of NA after dropping all the values
dim(h1n1)
```
From 26707 entries, we now have a total of 22976(a difference of 3731).

# CONVERTING NOMINAL DATA INTO NUMERIC DATA

```{r}
#duplicating dataset
h1n1_2 <- h1n1

h1n1_2[,32:33] <- NULL
#View(h1n1_2)
```

```{r}
#binarising the nominal attributes
binary_data <- dummyVars(~., data = h1n1_2)

#View(binary_data)

#adding the conversion to the data
new_data <- predict(binary_data, newdata = h1n1_2)
```

```{r}
#adding "h1n1_vaccine class" back to original dataset
new_data2 <- cbind(new_data, h1n1[32])

#View(new_data2)
```

```{r}
#converting 0 and 1 to "yes" and "no" for the decision class
new_data2$h1n1_vaccine <- factor(new_data2$h1n1_vaccine, levels = c(0, 1), labels = c("no", "yes"))
View(new_data2)
```

# DATA PREPROCESSING
Not needed since we are using random forest to train the model. And random forest is sensitive to feature scaling (but can perform normalization).

# TRAINING THE MODEL
```{r}
#ensuring reproducibility 
set.seed(123)

#applying training algorithms
lg_model <- glm(h1n1_vaccine~., data = new_data2, family = binomial)
```

```{r}
#summary(lg_model)
```

# TEST DATA
Applying on actual test data.
## LOADING THE DATA
```{r}
#load the validation labels
testing_data <- read.csv("test_set_features.csv", row.names = 1, header = T, stringsAsFactors = T)
View(testing_data)
```

## HANDLING MISSING VALUES
```{r}
colSums(is.na(testing_data))
```

```{r}
test_data <- testing_data
#removing "health_insurance" column from the dataset
test_data$health_insurance <- NULL

#also dropping "hhs_goe_region", "employment_industry" and "employment_occupation"
test_data$hhs_geo_region <- NULL
test_data$employment_industry <- NULL
test_data$employment_occupation <- NULL
```

```{r}
#dropping all NA values in the dataset
test_data <- na.omit(test_data)

#checking the dimension of NA after dropping all the values
dim(test_data)
```
22971 out of 26708(a difference of 3737).

## CONVERTING NOMINAL VALUES TO NUMERIC VALUES
```{r}
#binarising the nominal attributes
binary_data2 <- dummyVars(~., data = test_data)

#View(binary_data)

#adding the conversion to the data
test_data2 <- predict(binary_data2, newdata = test_data)
View(test_data2)
```

## VALIDATING THE MODEL
```{r}
#using dummyVars changes it to matrix so convert it back to a data.frame
test_data2 <- as.data.frame(test_data2)

#Predict on test data
testing <- predict(lg_model, test_data2, type = "response")

#testing
```

```{r}
#adding the probability to my test_set_features
test_data$h1n1_vaccine <- testing
View(test_data)
```


# TRAINING SEASONAL_VACCINE ALONE
```{r}
#adding "seasonal_vaccine class" back to original dataset
new_data3 <- cbind(new_data, h1n1[33])
```

```{r}
View(new_data3)
```

```{r}
#converting 0 and 1 to "yes" and "no" for the decision class
new_data3$seasonal_vaccine <- factor(new_data3$seasonal_vaccine, levels = c(0, 1), labels = c("no", "yes"))
View(new_data3)
```

# DATA PREPROCESSING
Not needed since we are using random forest to train the model. And random forest is sensitive to feature scaling (but can perform normalization).


# TRAINING THE MODEL
```{r}
#ensuring reproducibility 
set.seed(123)

#applying training algorithms
seasonal_lg_model <- glm(seasonal_vaccine~., data = new_data3, family = binomial)
```

```{r}
summary(seasonal_lg_model)
```

## VALIDATING THE MODEL (ASSITED WITH AI)
```{r}
#using dummyVars changes it to matrix so convert it back to a data.frame
test_data2 <- as.data.frame(test_data2)

#Predict on test data
testing2 <- predict(seasonal_lg_model, test_data2, type = "response")

#testing2
```

```{r}
#adding the probability to my test_set_features
test_data$seasonal_vaccine <- testing2
View(test_data)
```

```{r}
write.csv(test_data, "test_data.csv", row.names = TRUE)
```


```{r}
# Load required library
library(ggplot2)

# Extract model summary
model_summary <- summary(lg_model)

# Create a data frame with coefficients & p-values
importance_df <- as.data.frame(model_summary$coefficients[, c("Estimate", "Pr(>|z|)")])
colnames(importance_df) <- c("Coefficient", "P_value")

# Add significance label
importance_df$Significance <- ifelse(importance_df$P_value < 0.05, "Significant", "Not Significant")

# Sort by absolute coefficient size
importance_df <- importance_df[order(abs(importance_df$Coefficient), decreasing = TRUE), ]

# Plot feature importance
ggplot(importance_df, aes(x = reorder(rownames(importance_df), abs(Coefficient)), y = Coefficient, fill = Significance)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  scale_fill_manual(values = c("Significant" = "red", "Not Significant" = "gray")) +
  labs(title = "Feature Importance in Logistic Regression",
       x = "Features", y = "Coefficient") +
  theme_minimal()
```
```{r}
# Extract coefficients and p-values
model_summary <- summary(seasonal_lg_model)
coefficients <- model_summary$coefficients[, "Estimate"]
p_values <- model_summary$coefficients[, "Pr(>|z|)"]

# Create a data frame
importance_df <- data.frame(
  Variable = names(coefficients),
  Coefficient = coefficients,
  P_value = p_values,
  Significance = ifelse(p_values < 0.05, "Significant", "Not Significant")
)

# Sort by absolute coefficient size
importance_df_sorted <- importance_df[order(abs(importance_df$Coefficient), decreasing = TRUE), ]

# Load ggplot2
library(ggplot2)

# Plot bar chart of feature importance
ggplot(importance_df_sorted, aes(x = reorder(Variable, abs(Coefficient)), y = Coefficient, fill = Significance)) +
  geom_bar(stat = "identity", show.legend = TRUE) +
  coord_flip() +
  scale_fill_manual(values = c("Significant" = "red", "Not Significant" = "gray")) +
  labs(title = "Feature Importance in Logistic Regression Model",
       x = "Features", y = "Coefficient") +
  theme_minimal()

```

```{r}
library(ggplot2)

# Extract significant variables
importance_df <- data.frame(
  Variable = names(coefficients),
  Coefficient = coefficients,
  P_value = p_values
)

# Filter only significant variables (p-value < 0.05)
importance_df <- importance_df[importance_df$P_value < 0.05, ]

# Plot feature importance
ggplot(importance_df, aes(x = reorder(Variable, abs(Coefficient)), y = Coefficient, fill = Coefficient > 0)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Feature Importance in Vaccine Prediction Model", x = "Variable", y = "Coefficient") +
  theme_minimal()

```

```{r}
ggplot(test_data, aes(x = h1n1_vaccine)) +
  geom_density(fill = "blue", alpha = 0.4) +
  labs(title = "Distribution of Predicted Probabilities for H1N1 Vaccine", x = "Predicted Probability", y = "Density") +
  theme_minimal()

```
```{r}
ggplot(test_data, aes(x = seasonal_vaccine)) +
  geom_density(fill = "blue", alpha = 0.4) +
  labs(title = "Distribution of Predicted Probabilities for SEASONAL Vaccine", x = "Predicted Probability", y = "Density") +
  theme_minimal()

```

